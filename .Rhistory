count_gdp %>%
dplyr::group_by(CNTR_CODE) %>%
dplyr::summarise(
time_min = first(time),
time_max = last(time),
tot_nuts = max(tot_nuts)
) %>%
arrange(desc(tot_nuts))
# count_gdp %>%
#   filter(CNTR_CODE == "FR")
#
# gdp %>% head()
# (función para saber la disponibilidad de datos de las tablas de Eurostat)
s_t_eurostat <- function(data){
data %>%
mutate(geo_char = as.character(geo)) %>%
mutate(LEVL_CODE = case_when(
nchar(geo_char) == 3 + 2 ~ 3,
nchar(geo_char) == 2 + 2 ~ 2,
nchar(geo_char) == 1 + 2 ~ 1,
nchar(geo_char) == 0 + 2 ~ 0,
),
CNTR_CODE = substr(geo_char, 1, 2)) %>%
dplyr::group_by(CNTR_CODE) %>%
dplyr::summarise(
time_min = last(time),
time_max = first(time),
n_obs = n()
) %>%
arrange(time_min, desc(n_obs))
}
down_eurostat <- function(eurostat_str){
name_df <- get_eurostat(eurostat_str,
time_format = "num")
name_df %>% head() %>% print()
s_t_eurostat(name_df) %>% print()
name_df <- filter_nuts(name_df, 3)
return(name_df)
}
# list_euro_data <- c("nama_10r_3gdp", "nama_10r_3gva")
# Gross domestic product (GDP) at current market prices by NUTS 3 regions
down_eurostat("nama_10r_3gdp") -> e_gdp
e_gdp <- e_gdp %>%
filter((unit %in% c("MIO_EUR", "EUR_HAB", "MIO_PPS")))
# Filter all other indicators such as "milion units of national currenct or EU %.
gdp$unit %>% table()
gdp %>% head()
write.csv(gdp, file = "eurostat_gdp.csv")
# Gross value added at basic prices by NUTS 3 regions
down_eurostat("nama_10r_3gva") -> e_gva
e_gva$currency %>% table()
e_gdp %>%
mutate(CNTR_CODE = substr(geo, 1, 2) %>% as.factor()) %>%
select(CNTR_CODE) %>% table()
# Get it:
old_gdp <- read_delim("France data/refin.nama_10r_3gdp.dat",
"\t", escape_double = FALSE, trim_ws = TRUE,
col_types = cols(obs_decimals = col_skip(),
obs_status = col_skip()))
old_gdp %>% summary()
# s_t_eurostat(old_gdp) # DOES NOT WORK HERE
old_gdp <- old_gdp %>%
mutate(CNTR_CODE = substr(geo, 1, 2) %>% as.factor()) %>%
filter_nuts(3) %>%
filter((unit %in% c("MIO_EUR", "EUR_HAB", "MIO_PPS")))
old_gdp %>% dplyr::filter(CNTR_CODE == "FR") %>%
select(time) %>% summary() # Poland too! :)
table((old_gdp %>% dplyr::filter(CNTR_CODE == "PL"))$time) # %>% plot(type = 'l')
# Include it in the big table:
# old_gdp %>%
#   filter(CNTR_CODE %in% c("PL")) %>%
#   filter(time == 2015) -> pre_change
#
# old_gdp %>%
#   filter(CNTR_CODE %in% c("PL")) %>%
#   select(geo) %>%
#   unique() %>%
#   nrow()
#
# e_gdp %>%
#   mutate(CNTR_CODE = substr(geo, 1, 2) %>% as.factor()) %>%
#   filter(CNTR_CODE %in% c("PL")) %>%
#   select(geo) %>%
#   unique() %>%
#   nrow()
dict_2013_2016 <- readxl::read_excel("~/A - Estudios/LSE - Applied Social Data Science/Project/PM2.5/NUTS3/NUTS2013-NUTS2016.xlsx",
sheet = "Correspondence NUTS-3")
dict_2013_2016 <- readxl::read_excel("~/A - Estudios/LSE_ASDS/Project/PM2.5/NUTS3/NUTS2013-NUTS2016.xlsx",
sheet = "Correspondence NUTS-3")
# THIS IS ALSO EXCLUDING SOME (VERY FIEW) ZONES WHERE IT IS POSSIBLE TO ASSIGN VALUES (LOOK AT `COMPATIBLE` COLLUMN)
old_gdp_new_codes <- dict_2013_2016 %>%
filter(Change == "recoded") %>%
select(`Code 2013`, `Code 2016`) %>%
right_join(old_gdp, by = c("Code 2013" = "geo")) %>%  #
mutate(geo = ifelse(test = is.na(`Code 2016`),
yes = `Code 2013`,
no = `Code 2016`))  # %>%  filter(`Code 2013` == "FR241")
old_gdp_new_codes %>% summary()
old_gdp %>% filter(geo == "UKN01", # Old belfast
unit == "MIO_EUR") %>%
select(unit, geo, time, obs_value) %>%
left_join(y = e_gdp %>% filter(geo == "UKN06", # New belfast
unit == "MIO_EUR"), by = "time")
old_gdp %>% filter(geo == "FR711", # Old Ain
unit == "MIO_EUR") %>%
select(unit, geo, time, obs_value) %>%
full_join(y = e_gdp %>% filter(geo == "FRK21", # New Ain (France)
unit == "MIO_EUR"), by = "time")
old_gdp %>% filter(geo == "FR101", # Old Ain
unit == "MIO_EUR") %>%
select(unit, geo, time, obs_value) %>%
full_join(y = e_gdp %>% filter(geo == "FR101", # New Ain (France)
unit == "MIO_EUR"), by = "time")
# The `unjustified` growth of Paris is of a 0.15%
100*(212410.4-212091)/212091
# Differences all arround
old_gdp %>% filter(unit == "MIO_EUR") %>%
select(unit, geo, time, obs_value) %>%
full_join(y = e_gdp %>% filter(unit == "MIO_EUR"), by = c("geo", "time")) %>%
mutate(increase = 100*(values-obs_value)/obs_value) -> test_change
mean(test_change$increase, na.rm = TRUE)
hist(test_change$increase, breaks = 50, xlim = c(-10, 10))
old_gdp_new_codes %>%
#filter(time < 2015) %>% # Exclude 2015
full_join(e_gdp) %>%  #filter(geo == "FRK21", unit == "MIO_EUR")  %>% # New Ain (France, example)
mutate(values = ifelse(test = is.na(values), yes = obs_value, no = values),
CNTR_CODE = substr(geo, 1, 2)) %>%
select(unit, time, geo, values, CNTR_CODE) -> e_gdp_complete
# Review I now have data for all the years (yes!)
e_gdp_complete %>%
dplyr::group_by(as.character(CNTR_CODE)) %>%
arrange(desc(time)) %>%
dplyr::summarise(
time_min = last(time),
time_max = first(time),
n_obs = n()
) %>%
arrange(time_min, desc(n_obs))
write.csv(e_gdp_complete, file = "eurostat_gdp_complete.csv")
gdp <- read.csv(file = "eurostat_gdp_complete.csv")
gdp %>% summary
emp %>% summary
gdp_wide <- gdp %>%
filter(unit == "MIO_EUR") %>%
select(values, geo, time) %>%
pivot_wider(names_from = time, values_from = values)
gdp_wide
emp_wide <- emp %>%
filter(time == 2017,
wstat == "Employees") %>%
select(nace_r2, values, geo) %>%
pivot_wider(names_from = nace_r2, values_from = values)
# Why aren't they of the same length?
length(unique(emp$geo))
length(unique(nuts.sf$NUTS_ID))
nuts.sf.data <- nuts.sf %>%
left_join(emp_wide, by = c("NUTS_ID" = "geo")) %>%
left_join(gdp_wide, by = c("NUTS_ID" = "geo"))
nuts.sf.data %>% as.data.frame() %>%
filter(is.na(`2001`) == FALSE) %>%
select(CNTR_CODE) %>%
table()
plot(nuts.sf.data["2016"], xlim = c(0, 20), ylim = c(30, 70))
nuts.sf.data %>% as.data.frame()
nuts.sf <- readOGR("data", "nuts_sf")
library("rgdal")
nuts.sf <- readOGR("data", "nuts_sf")
NUTS3_16@data <- NUTS3_16@data %>%
mutate(NUTS_NAME = NUTS_NAME %>% as.character())
Encoding(NUTS3_16@data$NUTS_NAME) <- "UTF-8"
# Convert to sf-objects
nuts.sf <- st_as_sf(NUTS3_16)
nuts.sf %>% as.data.frame() %>% head()
emp <- read.csv(file = "eurostat_employment.csv")
gdp <- read.csv(file = "eurostat_gdp_complete.csv")
gdp %>% summary
emp %>% summary
# emp %>% pivot_wider(names_from = nace_r2, id_cols = geo, values_from = values)
gdp_wide <- gdp %>%
filter(unit == "MIO_EUR") %>%
select(values, geo, time) %>%
pivot_wider(names_from = time, values_from = values)
gdp_wide
emp_wide <- emp %>%
filter(time == 2017,
wstat == "Employees") %>%
select(nace_r2, values, geo) %>%
pivot_wider(names_from = nace_r2, values_from = values)
# Why aren't they of the same length? ¿is it turkey?
length(unique(emp$geo))
length(unique(nuts.sf$NUTS_ID))
nuts.sf.data <- nuts.sf %>%
left_join(emp_wide, by = c("NUTS_ID" = "geo")) %>%
left_join(gdp_wide, by = c("NUTS_ID" = "geo"))
nuts.sf.data %>% as.data.frame() %>%
filter(is.na(`2001`) == FALSE) %>%
select(CNTR_CODE) %>%
table()
plot(nuts.sf.data["2016"],
xlim = c(0, 20), ylim = c(30, 70))
nuts.sf.data %>% as.data.frame()
emp %>% summary
emp_wide <- emp %>%
filter(time == 2017,
wstat == "Employed persons") %>%
select(nace_r2, values, geo) %>%
pivot_wider(names_from = nace_r2, values_from = values)
# Why aren't they of the same length? ¿is it turkey?
length(unique(emp$geo))
length(unique(nuts.sf$NUTS_ID))
nuts.sf.data <- nuts.sf %>%
left_join(emp_wide, by = c("NUTS_ID" = "geo")) %>%
left_join(gdp_wide, by = c("NUTS_ID" = "geo"))
nuts.sf.data %>% as.data.frame() %>%
filter(is.na(`2001`) == FALSE) %>%
select(CNTR_CODE) %>%
table()
install.packages('panelView')
library(panelView)
data(panelView)
turnout
panelView(turnout ~ policy_edr + policy_mail_in + policy_motor, data = turnout, index = c("abb","year"), xlab = "Year", ylab = "State")
nuts.sf %>%
left_join(emp, by = c("NUTS_ID" = "geo"))
nuts_try <- nuts.sf %>%
left_join(emp, by = c("NUTS_ID" = "geo"))
nuts_try
nuts_try %>% as.data.frame()
nuts_try <- nuts.sf %>%
left_join(gdp, by = c("NUTS_ID" = "geo"))
nuts_try %>% as.data.frame()
nuts_try %>% as.data.frame() -> nuts_try
head(nuts_try)
knitr::opts_chunk$set(echo = TRUE)
nuts.sf %>% as.data.frame() %>% head(20)
# To unite them I found out a wat yo do it with "sf" so I convert them into sf and then go back.
library(sf)
# Convert to sf-objects
nuts.sf <- st_as_sf(NUTS3_16)
uar_points.sf <- st_as_sf(uar_sp)
gzones_sp.sf <- st_as_sf(gzones_sp)
# Keep all "meuse.sf", sort by row.names(meuse.sf). Default overlay is "intersects".
uar_points.sf_nuts <- st_join(uar_points.sf, nuts.sf)
gzones_sp.sf_nuts <- st_join(gzones_sp.sf, nuts.sf)
gzones_sp.sf_nuts %>% as.data.frame() %>% head()
# st_contains(points.sf, nuts.sf)
plot(uar_points.sf_nuts)
plot(gzones_sp.sf_nuts)
plot(nuts.sf$geometry)
# Convert back to Spatial*
uar_nuts <- as(uar_points.sf_nuts, "Spatial")
gz_nuts <- as(gzones_sp.sf_nuts, "Spatial")
# srdf_meuse <- as(srdf_meuse, "Spatial")
# Create a variable of minimum time for gzones (GZ):
gzones_sp.sf_nuts %>% as.data.frame() %>%
dplyr::group_by(NUTS_ID) %>%
summarise(min_time = min(InPlaceSince)) -> min_time
# Mark NUTS 3 regions that have a city or point marked in eather UAR or GZ
nuts.sf <- nuts.sf %>%
mutate(
appl_uar = NUTS_ID %in% uar_points.sf_nuts$NUTS_ID,
appl_gz = NUTS_ID %in% gzones_sp.sf_nuts$NUTS_ID
# min_apl_date = gzones_sp.sf_nuts$min_time
) %>%
left_join(min_time) %>%
select(-c("FID")) # duplicated
# Mark NUTS 3 regions that have a city or point marked in eather UAR or GZ
nuts.sf <- nuts.sf %>%
mutate(
appl_uar = NUTS_ID %in% uar_points.sf_nuts$NUTS_ID,
appl_gz = NUTS_ID %in% gzones_sp.sf_nuts$NUTS_ID
# min_apl_date = gzones_sp.sf_nuts$min_time
) %>%
left_join(min_time) %>%
select(-c("FID")) # duplicated
names(nuts.sf)
names(min_time)
# Mark NUTS 3 regions that have a city or point marked in eather UAR or GZ
nuts.sf <- nuts.sf %>%
mutate(
appl_uar = NUTS_ID %in% uar_points.sf_nuts$NUTS_ID,
appl_gz = NUTS_ID %in% gzones_sp.sf_nuts$NUTS_ID,
min_apl_date = min_time
) %>%
# left_join(min_time) %>%
select(-c("FID")) # duplicated
# Mark NUTS 3 regions that have a city or point marked in eather UAR or GZ
nuts.sf <- nuts.sf %>%
mutate(
appl_uar = NUTS_ID %in% uar_points.sf_nuts$NUTS_ID,
appl_gz = NUTS_ID %in% gzones_sp.sf_nuts$NUTS_ID
# min_apl_date = gzones_sp.sf_nuts$min_time
) %>%
left_join(min_time) %>%
select(-c("FID")) # duplicated
# Mark NUTS 3 regions that have a city or point marked in eather UAR or GZ
nuts.sf <- nuts.sf %>%
mutate(
appl_uar = NUTS_ID %in% uar_points.sf_nuts$NUTS_ID,
appl_gz = NUTS_ID %in% gzones_sp.sf_nuts$NUTS_ID
# min_apl_date = gzones_sp.sf_nuts$min_time
) %>%
cbind(min_time) %>%
select(-c("FID")) # duplicated
# Mark NUTS 3 regions that have a city or point marked in eather UAR or GZ
nuts.sf <- nuts.sf %>%
mutate(
appl_uar = NUTS_ID %in% uar_points.sf_nuts$NUTS_ID,
appl_gz = NUTS_ID %in% gzones_sp.sf_nuts$NUTS_ID
# min_apl_date = gzones_sp.sf_nuts$min_time
) %>%
select(-c("FID")) %>% # duplicated
cbind(min_time)
nuts.sf %>% as.data.frame() %>% head(20)
gzones_sp.sf_nuts %>% as.data.frame() %>%
dplyr::group_by(NUTS_ID) %>%
summarise(min_time = min(InPlaceSince))[,1] -> min_time
gzones_sp.sf_nuts %>% as.data.frame() %>%
dplyr::group_by(NUTS_ID) %>%
summarise(min_time = min(InPlaceSince))[,1] -> min_time
gzones_sp.sf_nuts %>% as.data.frame() %>%
dplyr::group_by(NUTS_ID) %>%
summarise(min_time = min(InPlaceSince))
nuts.sf
gzones_sp.sf_nuts %>% as.data.frame() %>%
dplyr::group_by(NUTS_ID) %>%
summarise(min_time = min(InPlaceSince)) -> min_time
min_time
gzones_sp.sf_nuts %>% as.data.frame() %>%
dplyr::group_by(NUTS_ID)
library(dplyr)
gzones_sp.sf_nuts %>% as.data.frame() %>%
dplyr::group_by(NUTS_ID) %>%
summarise(min_time = min(InPlaceSince)) -> min_time
min_time
gzones_sp.sf_nuts %>% as.data.frame() %>%
group_by(NUTS_ID) %>%
summarise(min_time = min(InPlaceSince)) -> min_time
min_time
gzones_sp.sf_nuts %>% as.data.frame() %>%
dplyr::group_by(NUTS_ID) %>%
summarise(min_time = min(InPlaceSince)) -> min_time
min_time
gzones_sp.sf_nuts %>% as.data.frame() %>%
dplyr::group_by(NUTS_ID) %>%
dplyr::summarise(min_time = min(InPlaceSince)) -> min_time
min_time
# Mark NUTS 3 regions that have a city or point marked in eather UAR or GZ
nuts.sf <- nuts.sf %>%
mutate(
appl_uar = NUTS_ID %in% uar_points.sf_nuts$NUTS_ID,
appl_gz = NUTS_ID %in% gzones_sp.sf_nuts$NUTS_ID
# min_apl_date = gzones_sp.sf_nuts$min_time
) %>%
left_join(min_time) %>%
select(-c("FID")) # duplicated
# To unite them I found out a wat yo do it with "sf" so I convert them into sf and then go back.
library(sf)
# Convert to sf-objects
nuts.sf <- st_as_sf(NUTS3_16)
uar_points.sf <- st_as_sf(uar_sp)
gzones_sp.sf <- st_as_sf(gzones_sp)
# Keep all "meuse.sf", sort by row.names(meuse.sf). Default overlay is "intersects".
uar_points.sf_nuts <- st_join(uar_points.sf, nuts.sf)
gzones_sp.sf_nuts <- st_join(gzones_sp.sf, nuts.sf)
gzones_sp.sf_nuts %>% as.data.frame() %>% head()
# st_contains(points.sf, nuts.sf)
plot(uar_points.sf_nuts)
plot(gzones_sp.sf_nuts)
plot(nuts.sf$geometry)
# Convert back to Spatial*
uar_nuts <- as(uar_points.sf_nuts, "Spatial")
gz_nuts <- as(gzones_sp.sf_nuts, "Spatial")
# srdf_meuse <- as(srdf_meuse, "Spatial")
# Create a variable of minimum time for gzones (GZ):
gzones_sp.sf_nuts %>% as.data.frame() %>%
dplyr::group_by(NUTS_ID) %>%
dplyr::summarise(min_time = min(InPlaceSince)) -> min_time
# Mark NUTS 3 regions that have a city or point marked in eather UAR or GZ
nuts.sf <- nuts.sf %>%
mutate(
appl_uar = NUTS_ID %in% uar_points.sf_nuts$NUTS_ID,
appl_gz = NUTS_ID %in% gzones_sp.sf_nuts$NUTS_ID
# min_apl_date = gzones_sp.sf_nuts$min_time
) %>%
left_join(min_time) %>%
select(-c("FID")) # duplicated
nuts.sf %>% as.data.frame() %>% head(20)
st_write(obj = nuts.sf, "data/nuts_sf.shp")
st_write(obj = nuts.sf, "data/nuts_sf.shp", delete_layer = TRUE)
library(jsonlite)
library(tidyverse)
library(rvest)
library(sf)
library("rgdal")
nuts.sf <- readOGR("data", "nuts_sf")
NUTS3_16@data <- NUTS3_16@data %>%
mutate(NUTS_NAME = NUTS_NAME %>% as.character())
Encoding(NUTS3_16@data$NUTS_NAME) <- "UTF-8"
# Convert to sf-objects
nuts.sf <- st_as_sf(NUTS3_16)
nuts.sf %>% as.data.frame() %>% head()
nuts.sf %>% as.data.frame() %>% head(20)
# To unite them I found out a wat yo do it with "sf" so I convert them into sf and then go back.
library(sf)
# Convert to sf-objects
nuts.sf <- st_as_sf(NUTS3_16)
uar_points.sf <- st_as_sf(uar_sp)
gzones_sp.sf <- st_as_sf(gzones_sp)
# Keep all "meuse.sf", sort by row.names(meuse.sf). Default overlay is "intersects".
uar_points.sf_nuts <- st_join(uar_points.sf, nuts.sf)
gzones_sp.sf_nuts <- st_join(gzones_sp.sf, nuts.sf)
gzones_sp.sf_nuts %>% as.data.frame() %>% head()
# st_contains(points.sf, nuts.sf)
plot(uar_points.sf_nuts)
plot(gzones_sp.sf_nuts)
plot(nuts.sf$geometry)
# Convert back to Spatial*
uar_nuts <- as(uar_points.sf_nuts, "Spatial")
gz_nuts <- as(gzones_sp.sf_nuts, "Spatial")
# srdf_meuse <- as(srdf_meuse, "Spatial")
# Create a variable of minimum time for gzones (GZ):
gzones_sp.sf_nuts %>% as.data.frame() %>%
dplyr::group_by(NUTS_ID) %>%
dplyr::summarise(min_time = min(InPlaceSince)) -> min_time
nuts.sf <- readOGR("data", "nuts_sf")
nuts.sf@data <- nuts.sf@data %>%
mutate(NUTS_NAME = NUTS_NAME %>% as.character())
Encoding(nuts.sf@data$NUTS_NAME) <- "UTF-8"
# Convert to sf-objects
nuts.sf <- st_as_sf(nuts.sf)
# Convert to sf-objects
nuts.sf <- st_as_sf(nuts.sf)
nuts.sf %>% as.data.frame() %>% head()
emp <- read.csv(file = "eurostat_employment.csv")
gdp <- read.csv(file = "eurostat_gdp_complete.csv")
gdp %>% summary
emp %>% summary
# emp %>% pivot_wider(names_from = nace_r2, id_cols = geo, values_from = values)
gdp_wide <- gdp %>%
filter(unit == "MIO_EUR") %>%
select(values, geo, time) %>%
pivot_wider(names_from = time, values_from = values)
gdp_wide
emp_wide <- emp %>%
filter(time == 2017,
wstat == "Employed persons") %>%
select(nace_r2, values, geo) %>%
pivot_wider(names_from = nace_r2, values_from = values)
# Why aren't they of the same length? ¿is it turkey?
length(unique(emp$geo))
length(unique(nuts.sf$NUTS_ID))
nuts.sf.data <- nuts.sf %>%
left_join(emp_wide, by = c("NUTS_ID" = "geo")) %>%
left_join(gdp_wide, by = c("NUTS_ID" = "geo"))
# Which cities do I have data of?
nuts.sf.data %>% as.data.frame() %>%
filter(is.na(`2001`) == FALSE) %>%
select(CNTR_CODE) %>%
table()
# NO DATA OF: AL, Switzerland/CH, IS, LI, ME, NO, RS, TR
plot(nuts.sf.data["2016"],
xlim = c(0, 20), ylim = c(30, 70))
nuts.sf.data %>% as.data.frame()
# install.packages('panelView')
library(panelView)
data(panelView)
turnout
panelView(turnout ~ policy_edr + policy_mail_in + policy_motor, data = turnout, index = c("abb","year"), xlab = "Year", ylab = "State")
nuts_try <- nuts.sf %>%
left_join(gdp, by = c("NUTS_ID" = "geo"))
nuts_try %>% as.data.frame() -> nuts_try
head(nuts_try)
nuts.sf %>% as.data.frame() %>% head()
nuts.sf %>% as.data.frame() %>% head()
nuts_try
turnout
nuts_try
nuts_try <- nuts.sf %>%
left_join(gdp %>% filter(unit == "MIO_EUR"), by = c("NUTS_ID" = "geo"))
nuts_try %>% as.data.frame() -> nuts_try
nuts_try
nuts_try
panelView(turnout ~ policy_edr + policy_mail_in + policy_motor, data = turnout, index = c("abb","year"), xlab = "Year", ylab = "State")
names(nuts_try)
0, appl_uar))
nuts_try %>%
mutate(appl_uar == ifelse((time < min_time | is.na(min_time),
nuts_try %>%
mutate(appl_uar == ifelse((time < min_time | is.na(min_time),
nuts_try %>%
mutate(appl_uar == ifelse((time < min_time | is.na(min_time)),
0, appl_uar))
nuts_try %>%
mutate(min_time = as.date(min_time),
appl_uar == ifelse((time < min_time | is.na(min_time)),
0, appl_uar))
load("~/A - Estudios/LSE_ASDS/Project/PM2.5/NUTS3/NUTS divisions in Europe.R")
load("~/A - Estudios/LSE_ASDS/Project/PM2.5/NUTS3/NUTS divisions in Europe.R")
library("rgdal")
library(leafgl)
library("leaflet")
# Source: https://ec.europa.eu/eurostat/web/gisco/geodata/reference-data/administrative-units-statistical-units/nuts
# (higher quality available)
basis <- "~/A - Estudios/LSE - Applied Social Data Science/Project/PM2.5/NUTS3/"
e2016 <- "ref-nuts-2016-01m/NUTS_RG_01M_2016_4326.shp/"
e2013 <- "ref-nuts-2013-10m.shp/"
wd2016 <- paste(basis, e2016, sep = "")
wd2013 <- paste(basis, e2013, sep = "")
urau_2018 <- paste0(basis, "URAU_2018")
########### NUTS 1, 2 and 3 of 2016 ###############
setwd(wd2016)
